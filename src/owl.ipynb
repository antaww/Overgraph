{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# |exporti\n",
    "\n",
    "import dateutil.parser as dparser\n",
    "import pandas as pd\n",
    "from streamlit_jupyter import StreamlitPatcher"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "sp = StreamlitPatcher()\n",
    "sp.jupyter()  # register patcher with streamlit"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e2936994752ffeb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# |exporti\n",
    "import os\n",
    "\n",
    "project_name = 'Overgraph'\n",
    "path = os.getcwd().split(project_name)[0] + project_name\n",
    "owl_path = f'{path}/src/datas/owl'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e40769f2e005bab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# |exporti\n",
    "datas = {\n",
    "    # https://drive.google.com/file/d/1tPx0GVfdcdJUEl57ytA_uJtArKszI4vJ/view?usp=sharing\n",
    "    # Google Docs\n",
    "    # match_map_stats.csv\n",
    "    'match_map_stats.csv': '1tPx0GVfdcdJUEl57ytA_uJtArKszI4vJ',\n",
    "    # https://drive.google.com/file/d/1Gi0mbtmjOpcGeEBYjb9iAQiodIxd9cw_/view?usp=sharing\n",
    "    # Google Docs\n",
    "    # phs_2018_playoffs.csv\n",
    "    'phs_2018_playoffs.csv': '1Gi0mbtmjOpcGeEBYjb9iAQiodIxd9cw_',\n",
    "    # https://drive.google.com/file/d/1SfBAigf9vclOCyHYP2-uyp24J5mbdLN7/view?usp=sharing\n",
    "    # Google Docs\n",
    "    # phs_2018_stage_1.csv\n",
    "    'phs_2018_stage_1.csv': '1SfBAigf9vclOCyHYP2-uyp24J5mbdLN7',\n",
    "    # https://drive.google.com/file/d/1PUQKvE37wp14NII8FXqsTigTlSOmYtg-/view?usp=sharing\n",
    "    # Google Docs\n",
    "    # phs_2018_stage_2.csv\n",
    "    'phs_2018_stage_2.csv': '1PUQKvE37wp14NII8FXqsTigTlSOmYtg-',\n",
    "    # https://drive.google.com/file/d/1HhPL5MODUIkAABjgBOkIZfSuC7g4gKaG/view?usp=sharing\n",
    "    # Google Docs\n",
    "    # phs_2018_stage_3.csv\n",
    "    'phs_2018_stage_3.csv': '1HhPL5MODUIkAABjgBOkIZfSuC7g4gKaG',\n",
    "    # https://drive.google.com/file/d/1xhUj33D7kkZsEMU6UaORBAFs3jSDrI17/view?usp=sharing\n",
    "    # Google Docs\n",
    "    # phs_2018_stage_4.csv\n",
    "    'phs_2018_stage_4.csv': '1xhUj33D7kkZsEMU6UaORBAFs3jSDrI17',\n",
    "    # https://drive.google.com/file/d/13Knx8WlSemwDNYXd1YT0mYpljjHk-R4Y/view?usp=sharing\n",
    "    # Google Docs\n",
    "    # phs_2019_playoffs.csv\n",
    "    'phs_2019_playoffs.csv': '13Knx8WlSemwDNYXd1YT0mYpljjHk-R4Y',\n",
    "    # https://drive.google.com/file/d/1dCGQsAvS9xaGIrEhHhjf9NDVTL2hk2qP/view?usp=sharing\n",
    "    # Google Docs\n",
    "    # phs_2019_stage_1.csv\n",
    "    'phs_2019_stage_1.csv': '1dCGQsAvS9xaGIrEhHhjf9NDVTL2hk2qP',\n",
    "    # https://drive.google.com/file/d/1yavjUuNO_O7fxT9PGZS8AyQpau_eZpWj/view?usp=sharing\n",
    "    # Google Docs\n",
    "    # phs_2019_stage_2.csv\n",
    "    'phs_2019_stage_2.csv': '1yavjUuNO_O7fxT9PGZS8AyQpau_eZpWj',\n",
    "    # https://drive.google.com/file/d/1WS7btQ8HC_t_t9OAp4UCQd5O1cdGsvVA/view?usp=sharing\n",
    "    # Google Docs\n",
    "    # phs_2019_stage_3.csv\n",
    "    'phs_2019_stage_3.csv': '1WS7btQ8HC_t_t9OAp4UCQd5O1cdGsvVA',\n",
    "    # https://drive.google.com/file/d/1fWNKo0HfWM2CQzi-6WbUK1duvBd0NQiN/view?usp=sharing\n",
    "    # Google Docs\n",
    "    # phs_2019_stage_4.csv\n",
    "    'phs_2019_stage_4.csv': '1fWNKo0HfWM2CQzi-6WbUK1duvBd0NQiN',\n",
    "    # https://drive.google.com/file/d/1z7_MiS63noOB26Kxtbf5mwbVzTUPv1DG/view?usp=sharing\n",
    "    # Google Docs\n",
    "    # phs_2020_1.csv\n",
    "    'phs_2020_1.csv': '1z7_MiS63noOB26Kxtbf5mwbVzTUPv1DG',\n",
    "    # https://drive.google.com/file/d/1ZWAvP5eDs2EDYiuuZLcBWRI8PgY2aiSD/view?usp=sharing\n",
    "    # Google Docs\n",
    "    # phs_2020_2.csv\n",
    "    'phs_2020_2.csv': '1ZWAvP5eDs2EDYiuuZLcBWRI8PgY2aiSD',\n",
    "    # https://drive.google.com/file/d/1SJ5T4_8YyE-fv8flntKoboXToEupP1qE/view?usp=sharing\n",
    "    # Google Docs\n",
    "    # phs_2021_1.csv\n",
    "    'phs_2021_1.csv': '1SJ5T4_8YyE-fv8flntKoboXToEupP1qE',\n",
    "    # https://drive.google.com/file/d/1QN5kH1ZwPUwcxjH_XqB2OadfL4qB6IFX/view?usp=sharing\n",
    "    # Google Docs\n",
    "    # phs_2022.csv\n",
    "    'phs_2022.csv': '1QN5kH1ZwPUwcxjH_XqB2OadfL4qB6IFX',\n",
    "    # https://drive.google.com/file/d/1fKsztKPxxDbBdmLLH0WCV_GUsFcJhBph/view?usp=sharing\n",
    "    # Google Docs\n",
    "    # phs_2023.csv\n",
    "    'phs_2023.csv': '1fKsztKPxxDbBdmLLH0WCV_GUsFcJhBph',\n",
    "    # https://drive.google.com/file/d/1peF54UifbGSN9skYG2Ky2k7lMyUgIPO3/view?usp=sharing\n",
    "    # Google Docs\n",
    "    # switch.csv\n",
    "    'switch.csv': '1peF54UifbGSN9skYG2Ky2k7lMyUgIPO3'\n",
    "}\n",
    "\n",
    "url = 'https://drive.google.com/uc?export=download&id=%s'"
   ],
   "id": "d29e3e801d61cd9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MAPS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d070459e9200c8b0"
  },
  {
   "cell_type": "code",
   "source": [
    "# |export\n",
    "# map_stats = pd.read_csv(f'{owl_path}/match_map_stats.csv')\n",
    "map_stats = pd.read_csv(url % datas['match_map_stats.csv'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "430f11901d665e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2018 STAGE 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fedaf35c47762b6f"
  },
  {
   "cell_type": "code",
   "source": [
    "# |exporti\n",
    "# df_2018_s1 = pd.read_csv(f'{owl_path}/phs_2018_stage_1.csv')\n",
    "df_2018_s1 = pd.read_csv(url % datas['phs_2018_stage_1.csv'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae71f4d91bb0dad5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df_2018_s1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8f655ce086ea1b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2018 STAGE 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b1f51fab3dc6a59"
  },
  {
   "cell_type": "code",
   "source": [
    "# |exporti\n",
    "# df_2018_s2 = pd.read_csv(f'{owl_path}/phs_2018_stage_2.csv')\n",
    "df_2018_s2 = pd.read_csv(url % datas['phs_2018_stage_2.csv'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afc06707722d7660",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df_2018_s2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6822f1b3bc0103a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2018 STAGE 3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e44f8484353a9bf"
  },
  {
   "cell_type": "code",
   "source": [
    "# |exporti\n",
    "# df_2018_s3 = pd.read_csv(f'{owl_path}/phs_2018_stage_3.csv')\n",
    "df_2018_s3 = pd.read_csv(url % datas['phs_2018_stage_3.csv'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a29a2634f35346f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df_2018_s3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c443a94b249fd428",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2018 STAGE 4"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8e6220b55a18269"
  },
  {
   "cell_type": "code",
   "source": [
    "# |exporti\n",
    "# df_2018_s4 = pd.read_csv(f'{owl_path}/phs_2018_stage_4.csv')\n",
    "df_2018_s4 = pd.read_csv(url % datas['phs_2018_stage_4.csv'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd0b2d17a2727a20",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df_2018_s4"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5495d6682805f3bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2018 PLAYOFFS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65d01c2b31074ef1"
  },
  {
   "cell_type": "code",
   "source": [
    "# |exporti\n",
    "# df_2018_po = pd.read_csv(f'{owl_path}/phs_2018_playoffs.csv')\n",
    "df_2018_po = pd.read_csv(url % datas['phs_2018_playoffs.csv'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "601d38346d8fb1fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df_2018_po"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca51f63d5c712272",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2019 STAGE 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "476eec10af4d6220"
  },
  {
   "cell_type": "code",
   "source": [
    "# |exporti\n",
    "# df_2019_s1 = pd.read_csv(f'{owl_path}/phs_2019_stage_1.csv')\n",
    "df_2019_s1 = pd.read_csv(url % datas['phs_2019_stage_1.csv'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7c744f5ff8a32f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df_2019_s1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba50696b0f72f5a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2019 STAGE 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4eb6e02ffdaffa00"
  },
  {
   "cell_type": "code",
   "source": [
    "# |exporti\n",
    "# df_2019_s2 = pd.read_csv(f'{owl_path}/phs_2019_stage_2.csv')\n",
    "df_2019_s2 = pd.read_csv(url % datas['phs_2019_stage_2.csv'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4aa2a5e715ac8790",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df_2019_s2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "845ee1781bfa5f8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2019 STAGE 3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0ea23af7e5877be"
  },
  {
   "cell_type": "code",
   "source": [
    "# |exporti\n",
    "# df_2019_s3 = pd.read_csv(f'{owl_path}/phs_2019_stage_3.csv')\n",
    "df_2019_s3 = pd.read_csv(url % datas['phs_2019_stage_3.csv'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ec37fb764a37d6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df_2019_s3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d79668f0958771fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2019 STAGE 4"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "169aca4202c080a8"
  },
  {
   "cell_type": "code",
   "source": [
    "# |exporti\n",
    "# df_2019_s4 = pd.read_csv(f'{owl_path}/phs_2019_stage_4.csv')\n",
    "df_2019_s4 = pd.read_csv(url % datas['phs_2019_stage_4.csv'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1139c720bd0d9602",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df_2019_s4"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de265edd7486d1e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2019 PLAYOFFS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "258d3d09ad9baaa9"
  },
  {
   "cell_type": "code",
   "source": [
    "# |exporti\n",
    "# df_2019_po = pd.read_csv(f'{owl_path}/phs_2019_playoffs.csv')\n",
    "df_2019_po = pd.read_csv(url % datas['phs_2019_playoffs.csv'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7c34fc760fbba55",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df_2019_po"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d09479ebd112f14",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2020 STAGE 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "758b9254ffd7c77e"
  },
  {
   "cell_type": "code",
   "source": [
    "# |exporti\n",
    "# df_2020_s1 = pd.read_csv(f'{owl_path}/phs_2020_1.csv')\n",
    "df_2020_s1 = pd.read_csv(url % datas['phs_2020_1.csv'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a2cfa21f90612d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df_2020_s1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b330e51dcc6d11a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2020 STAGE 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c2f401924341244"
  },
  {
   "cell_type": "code",
   "source": [
    "# |exporti\n",
    "# df_2020_s2 = pd.read_csv(f'{owl_path}/phs_2020_2.csv')\n",
    "df_2020_s2 = pd.read_csv(url % datas['phs_2020_2.csv'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d258beaea2726aeb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df_2020_s2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af48fc760f5a616c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2021 STAGE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0e399cf79fdd603"
  },
  {
   "cell_type": "code",
   "source": [
    "# |exporti\n",
    "# df_2021 = pd.read_csv(f'{owl_path}/phs_2021_1.csv')\n",
    "df_2021 = pd.read_csv(url % datas['phs_2021_1.csv'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cd117336d6455e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df_2021"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed7eace15d3f8045",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2022 STAGE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bf7513ffeba41e2"
  },
  {
   "cell_type": "code",
   "source": [
    "# |exporti\n",
    "# df_2022 = pd.read_csv(f'{owl_path}/phs_2022.csv')\n",
    "df_2022 = pd.read_csv(url % datas['phs_2022.csv'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41672bf958b5759d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df_2022"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "848145f5694561",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2023 STAGE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77300b08a323f6cb"
  },
  {
   "cell_type": "code",
   "source": [
    "# |exporti\n",
    "# df_2023 = pd.read_csv(f'{owl_path}/phs_2023.csv')\n",
    "df_2023 = pd.read_csv(url % datas['phs_2023.csv'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c90b4df891bc6cba",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df_2023"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abdefd073a4ef70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SWITCH",
   "id": "b9111be7864c0a02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# |exporti\n",
    "# df_switch = pd.read_csv(f'{owl_path}/switch.csv')\n",
    "df_switch = pd.read_csv(url % datas['switch.csv'])"
   ],
   "id": "461160fe1fd6f4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MERGE DATAFRAMES"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9f44aa3cc12b1a7"
  },
  {
   "cell_type": "code",
   "source": [
    "# |export\n",
    "# merge every dataframes in one\n",
    "df = pd.concat(\n",
    "    [df_2018_s1, df_2018_s2, df_2018_s3, df_2018_s4, df_2018_po, df_2019_s1, df_2019_s2, df_2019_s3, df_2019_s4,\n",
    "     df_2019_po, df_2020_s1, df_2020_s2, df_2021, df_2022, df_2023])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae7a63da7d03489e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47f8c6c2861c3ba2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CLEAN DATA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47e536ff43c2f4a0"
  },
  {
   "cell_type": "code",
   "source": [
    "# |exporti\n",
    "df.replace({'hero': 'McCree'}, 'Cassidy', inplace=True)\n",
    "df.replace({'hero': 'Lucio'}, 'Lúcio', inplace=True)\n",
    "df.replace({'hero': 'Torbjorn'}, 'Torbjörn', inplace=True)\n",
    "df = df[df['map_type'].str.lower() != 'UNKNOWN'.lower()]\n",
    "df.replace({'team': 'Paris Eternal'}, 'Vegas Eternal', inplace=True)\n",
    "df.replace({'team': 'Philadelphia Fusion'}, 'Seoul Infernal', inplace=True)\n",
    "# todo: rework this part with 'start_time' year extraction and place it in 'stage'\n",
    "stage_2018 = ['Overwatch League - Stage 1', 'Overwatch League - Stage 2', 'Overwatch League - Stage 3',\n",
    "              'Overwatch League - Stage 4', 'Overwatch League - Stage 1 - Title Matches',\n",
    "              'Overwatch League - Stage 2 Title Matches',\n",
    "              'Overwatch League - Stage 3 Title Matches', 'Overwatch League - Stage 4 Title Matches',\n",
    "              'Overwatch League Inaugural Season Championship']\n",
    "stage_2019 = ['Overwatch League Stage 1', 'Overwatch League Stage 2', 'Overwatch League Stage 3',\n",
    "              'Overwatch League Stage 4', 'Overwatch League Stage 1 Title Matches',\n",
    "              'Overwatch League Stage 2 Title Matches', 'Overwatch League Stage 3 Title Matches',\n",
    "              'Overwatch League Stage 4 Title Matches', 'Overwatch League 2019 Post-Season']\n",
    "stage_2020 = ['OWL 2020 Regular Season', 'OWL APAC All-Stars', 'OWL North America All-Stars']\n",
    "stage_2021 = ['OWL 2021']\n",
    "stage_2022 = ['Kickoff Clash: Qualifiers', 'Kickoff Clash: Tournament', 'Midseason Madness: Qualifiers',\n",
    "              'Midseason Madness: Tournament', 'Summer Showdown: Qualifiers', 'Summer Showdown: Tournament',\n",
    "              'Countdown Cup: Qualifiers', 'Countdown Cup: Tournament', 'Postseason']\n",
    "stage_2023 = ['Pro-Am', 'Spring Qualifiers', 'Spring Knockouts', 'Midseason Madness', 'Summer Showdown',\n",
    "              'Countdown Cup', 'Postseason']\n",
    "\n",
    "for stage in stage_2018:\n",
    "    df.replace({'stage': stage}, f'2018 : {stage}', inplace=True)\n",
    "for stage in stage_2019:\n",
    "    df.replace({'stage': stage}, f'2019 : {stage}', inplace=True)\n",
    "for stage in stage_2020:\n",
    "    df.replace({'stage': stage}, f'2020 : {stage}', inplace=True)\n",
    "for stage in stage_2021:\n",
    "    df.replace({'stage': stage}, f'2021 : {stage}', inplace=True)\n",
    "for stage in stage_2022:\n",
    "    df.replace({'stage': stage}, f'2022 : {stage}', inplace=True)\n",
    "for stage in stage_2023:\n",
    "    df.replace({'stage': stage}, f'2023 : {stage}', inplace=True)\n",
    "\n",
    "dps_list = ['Ashe', 'Bastion', 'Cassidy', 'Echo', 'Genji', 'Hanzo', 'Junkrat', 'Mei', 'Pharah',\n",
    "            'Reaper', 'Sojourn', 'Soldier: 76', 'Sombra', 'Symmetra', 'Torbjörn', 'Tracer', 'Widowmaker']\n",
    "tank_list = ['D.Va', 'Doomfist', 'Junker Queen', 'Orisa', 'Ramattra', 'Reinhardt', 'Roadhog', 'Sigma', 'Winston',\n",
    "             'Wrecking Ball', 'Zarya']\n",
    "support_list = ['Ana', 'Baptiste', 'Brigitte', 'Illari', 'Kiriko', 'Lifeweaver', 'Lúcio', 'Mercy', 'Moira', 'Zenyatta']\n",
    "\n",
    "# Add a new column 'role' to the dataframe and fill it with the role of the hero\n",
    "df['role'] = df['hero']\n",
    "df.replace({'role': dps_list}, 'DPS', inplace=True)\n",
    "df.replace({'role': tank_list}, 'Tank', inplace=True)\n",
    "df.replace({'role': support_list}, 'Support', inplace=True)\n",
    "df.replace({'role': 'All Heroes'}, 'All', inplace=True)\n",
    "\n",
    "\n",
    "# !!!! to save execution time, match_map_stats.csv cleaned version has been saved\n",
    "# !!!! if it's your first run, you must uncomment the following part: \n",
    "# for col in ['match_winner', 'map_winner', 'map_loser', 'attacker', 'defender', 'team_one_name', 'team_two_name']:\n",
    "#     map_stats.replace({col: 'Paris Eternal'}, 'Vegas Eternal', inplace=True)\n",
    "#     map_stats.replace({col: 'Philadelphia Fusion'}, 'Seoul Infernal', inplace=True)\n",
    "# map_stats['round_start_time'] = map_stats['round_start_time'].str.replace(' UTC', '')\n",
    "# map_stats['round_end_time'] = map_stats['round_end_time'].str.replace(' UTC', '')\n",
    "# map_stats['round_start_time'] = map_stats['round_start_time'].apply(lambda x: dparser.parse(x, fuzzy=True))\n",
    "# map_stats['round_end_time'] = map_stats['round_end_time'].apply(lambda x: dparser.parse(x, fuzzy=True))\n",
    "# map_stats.to_csv(f'{owl_path}/match_map_stats.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd3d61ef96e05cfe",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PLAYGROUND"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efc94a3a6d74f1c8"
  },
  {
   "cell_type": "code",
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae366b829d48e921",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "map_stats.columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f0972d157d4eab7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df[df['role'] == 'Support']['stat'].unique()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f334aeffcca6487",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df_switch\n",
    "# first_heroes =  df_switch.drop_duplicates(subset=['player', 'map'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e5bc9bda506028b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# |export\n",
    "def get_match_analysis_heroes_played(stage: str, match: int, map: str, all: bool) -> pd.DataFrame:\n",
    "    # Filter the dataframe based on the stage and match_id\n",
    "    match_data = df[(df['stage'] == stage) & (df['match_id'] == match) & (df['map'] == map)]\n",
    "\n",
    "    # for each unique player, get unique 'hero' and 'stat' == 'Time Played' and 'stat_amount'\n",
    "    result = pd.DataFrame(columns=['Team', 'Player', 'Hero', 'Time Played'])\n",
    "    players = match_data['player'].unique()\n",
    "    for player in players:\n",
    "        player_data = match_data[match_data['player'] == player]\n",
    "        player_data = player_data[player_data['stat'] == 'Time Played']\n",
    "\n",
    "        # Filter the data based on the 'all' parameter\n",
    "        if all:\n",
    "            player_data = player_data[player_data['hero'] == 'All Heroes']\n",
    "        else:\n",
    "            player_data = player_data[player_data['hero'] != 'All Heroes']\n",
    "\n",
    "        player_data = player_data[['team', 'player', 'hero', 'stat_amount']]\n",
    "        player_data.columns = ['Team', 'Player', 'Hero', 'Time Played']\n",
    "        result = pd.concat([result, player_data], ignore_index=True, sort=False)\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a293ef601beba0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# get_match_analysis_heroes_played('2018 : Overwatch League - Stage 1', 10223, 'Dorado', all=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2283380744174cb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# |export\n",
    "def get_match_analysis_all_stats(stage: str, match: int, map: str) -> pd.DataFrame:\n",
    "    # Filter the dataframe based on the stage and match_id\n",
    "    match_data = df[(df['stage'] == stage) & (df['match_id'] == match) & (df['map'] == map)]\n",
    "\n",
    "    # List of common stats to calculate\n",
    "    stats_list = [\n",
    "        'All Damage Done', 'Assists', 'Eliminations', 'Eliminations per Life', 'Deaths', 'Final Blows',\n",
    "        'Hero Damage Done', 'Time Played', 'Ultimates Used', 'Objective Kills', 'Weapon Accuracy',\n",
    "        'Average Time Alive', 'Damage Blocked', 'Healing Done', 'Players Saved']\n",
    "\n",
    "    # get all these stat for the player : 'Team', 'Player', 'Hero', 'Role', 'Stat', 'Stat Amount'\n",
    "    result = pd.DataFrame(columns=['Team', 'Player', 'Hero', 'Role', 'Stat', 'Stat Amount'])\n",
    "\n",
    "    for stat in stats_list:\n",
    "        player_data = match_data[match_data['stat'] == stat]\n",
    "        # Filter the data based on the 'all' parameter\n",
    "        player_data = player_data[player_data['hero'] == 'All Heroes']\n",
    "        player_data = player_data[['team', 'player', 'hero', 'role', 'stat', 'stat_amount']]\n",
    "        player_data.columns = ['Team', 'Player', 'Hero', 'Role', 'Stat', 'Stat Amount']\n",
    "        result = pd.concat([result, player_data], ignore_index=True, sort=False)\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5de59ba6bdec510",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# get_match_analysis_all_stats('2018 : Overwatch League - Stage 1', 10223, 'Dorado')",
   "metadata": {
    "collapsed": false
   },
   "id": "c3d393206a61bab7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# |export\n",
    "def get_match_analysis_heroes_stats(stage: str, match: int, map: str, player: str, all: bool,\n",
    "                                    hero: str = None) -> pd.DataFrame:\n",
    "    # Filter the dataframe based on the stage and match_id\n",
    "    match_data = df[(df['stage'] == stage) & (df['match_id'] == match) & (df['map'] == map)]\n",
    "\n",
    "    # List of common stats to calculate\n",
    "    stats_list = ['All Damage Done', 'Assists', 'Eliminations', 'Eliminations per Life', 'Deaths', 'Final Blows',\n",
    "                  'Hero Damage Done', 'Time Played', 'Ultimates Used', 'Objective Kills', 'Weapon Accuracy',\n",
    "                  'Average Time Alive', 'Damage Blocked', 'Healing Done', 'Players Saved']\n",
    "\n",
    "    tank_stats = ['Damage Blocked']\n",
    "    support_stats = ['Healing Done', 'Players Saved']\n",
    "\n",
    "    # get all these stat for the player : 'Team', 'Player', 'Hero', 'Role', 'Stat', 'Stat Amount' \n",
    "    result = pd.DataFrame(columns=['Team', 'Player', 'Hero', 'Role', 'Stat', 'Stat Amount'])\n",
    "\n",
    "    for stat in stats_list:\n",
    "        player_data = match_data[(match_data['player'] == player) & (match_data['stat'] == stat)]\n",
    "        # Filter the data based on the 'all' parameter\n",
    "        if all:\n",
    "            player_data = player_data[player_data['hero'] == 'All Heroes']\n",
    "        else:\n",
    "            player_data = player_data[player_data['hero'] != 'All Heroes']\n",
    "\n",
    "        # Filter the data based on the 'hero' parameter\n",
    "        if hero is not None:\n",
    "            player_data = player_data[player_data['hero'] == hero]\n",
    "\n",
    "        player_data = player_data[['team', 'player', 'hero', 'role', 'stat', 'stat_amount']]\n",
    "\n",
    "        player_data.columns = ['Team', 'Player', 'Hero', 'Role', 'Stat', 'Stat Amount']\n",
    "        result = pd.concat([result, player_data], ignore_index=True, sort=False)\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "570449d877b479a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# get_match_analysis_heroes_stats('2018 : Overwatch League - Stage 1', 10223, 'Dorado', 'uNKOE', all=False)",
   "metadata": {
    "collapsed": false
   },
   "id": "90c6189144335f74",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# |export\n",
    "def get_team_profile(team: str, stat: str, stage: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function generates a profile for a given team, based on a specific statistic and optionally for a specific stage.\n",
    "    \n",
    "    Parameters:\n",
    "    team (str): The name of the team.\n",
    "    stat (str): The statistic to consider.\n",
    "    stage (str, optional): The stage to consider. If None, all stages are considered.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the team profile.\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter the DataFrame based on the team, stat, and hero\n",
    "    result = df[df['team'] == team]\n",
    "    result = result[result['stat'] == stat]\n",
    "    result = result[result['hero'] == 'All Heroes']\n",
    "\n",
    "    # If a stage is specified, filter the DataFrame based on the stage\n",
    "    if stage:\n",
    "        print('stage filter')\n",
    "        result = result[result['stage'] == stage]\n",
    "\n",
    "    # Calculate the total stat amount for each match\n",
    "    stat_result = result.groupby(['match_id'])['stat_amount'].sum()\n",
    "\n",
    "    # Calculate the total stat amount for each match and start time\n",
    "    total_stat_amount = result.groupby(['match_id', 'start_time'])['stat_amount'].sum()\n",
    "\n",
    "    # Calculate the number of start times for each match\n",
    "    number_of_start_time_per_match = total_stat_amount.groupby(['match_id']).count()\n",
    "\n",
    "    # Calculate the average stat amount\n",
    "    avg_stat = total_stat_amount.groupby(['match_id']).sum() / number_of_start_time_per_match\n",
    "\n",
    "    # Add the total and average stat amounts to the DataFrame\n",
    "    result['stat_match_total'] = result['match_id'].apply(lambda x: stat_result[x])\n",
    "    result['avg_stat'] = result['match_id'].apply(lambda x: avg_stat[x])\n",
    "\n",
    "    # Replace the stat amount with the total stat amount\n",
    "    result['stat_amount'] = result['stat_match_total']\n",
    "    result = result.drop(columns=['stat_match_total'])\n",
    "\n",
    "    # Merge the DataFrame with the map stats DataFrame\n",
    "    result = result.reset_index().merge(\n",
    "        map_stats[['match_id', 'match_winner', 'team_one_name', 'team_two_name']], on='match_id')\n",
    "\n",
    "    # Add the opponent team to the DataFrame\n",
    "    result['opponent'] = result['team_one_name']\n",
    "    result['opponent'] = result['opponent'].where(result['team_one_name'] != team, result['team_two_name'])\n",
    "    result = result.drop(columns=['team_one_name', 'team_two_name'])\n",
    "\n",
    "    # Remove duplicate matches\n",
    "    result = result.drop_duplicates(subset='match_id')\n",
    "    result = result.set_index('match_id')\n",
    "\n",
    "    # Convert the start time to a datetime object and sort the DataFrame by start time\n",
    "    result['start_time'] = result['start_time'].str.replace(' UTC', '')\n",
    "    result['start_time'] = result['start_time'].apply(lambda x: dparser.parse(x, fuzzy=True))\n",
    "    result = result.sort_values(by='start_time')\n",
    "\n",
    "    # Calculate the win rate for each match\n",
    "    result['winrate'] = 0\n",
    "    win = 0\n",
    "    loss = 0\n",
    "    for match in result.index:\n",
    "        if result.loc[match, 'match_winner'] == team:\n",
    "            win += 1\n",
    "        else:\n",
    "            loss += 1\n",
    "        result.loc[match, 'winrate'] = win / (win + loss) * 100\n",
    "\n",
    "    # Remove unnecessary columns\n",
    "    result = result.drop(columns=['index', 'stat', 'map_type', 'map', 'player', 'hero', 'team'])\n",
    "\n",
    "    # Rename the columns\n",
    "    result.rename(\n",
    "        columns={'start_time': 'Start Time', 'stat_amount': stat, 'match_winner': 'Match Winner', 'winrate': 'Winrate',\n",
    "                 'opponent': 'Opponent', 'stage': 'Stage', 'avg_stat': f'Avg {stat}'},\n",
    "        inplace=True)\n",
    "\n",
    "    result.index.name = 'Match ID'\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "398dcf28002011fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# get_team_profile('Vegas Eternal', 'Hero Damage Done')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9f978128baf33f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# |export\n",
    "def get_heroes_stat(stat: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function calculates the total amount of a specific statistic for each hero in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    stat (str): The statistic to consider.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the total amount of the statistic for each hero, sorted in descending order.\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame based on the statistic\n",
    "    result = df[df['stat'] == stat]\n",
    "\n",
    "    # # Group by hero and sum the statistic amounts\n",
    "    # result = result.groupby('hero')['stat_amount'].sum().sort_values(ascending=False)\n",
    "    # \n",
    "    # # Set the name of the Series and its index\n",
    "    # result.name = stat\n",
    "    # result.index.name = 'Hero'\n",
    "    # \n",
    "    # # Convert the Series to a DataFrame\n",
    "    # result = result.to_frame()\n",
    "\n",
    "    # get the sum of the stat for each hero : 'Hero', 'Role', 'Stat', 'Stat Amount'\n",
    "    result = result.groupby(['hero', 'role', 'stat'])['stat_amount'].sum().reset_index()\n",
    "    result = result[result['hero'] != 'All Heroes']\n",
    "    result = result.sort_values(by='stat_amount', ascending=False)\n",
    "    result = result.set_index('hero')\n",
    "\n",
    "    # Rename the columns\n",
    "    result.rename(columns={'role': 'Role', 'stat': 'Stat', 'stat_amount': stat}, inplace=True)\n",
    "    result.index.name = 'Hero'\n",
    "\n",
    "    return result\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "652979432107645a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# get_heroes_stat('Hero Damage Done')",
   "metadata": {
    "collapsed": false
   },
   "id": "7de4dd0240b4719c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# |export\n",
    "def get_players_stat(stat: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function calculates the total amount of a specific statistic for each player in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    stat (str): The statistic to consider.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the total amount of the statistic for each player, sorted in descending order.\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame based on the statistic\n",
    "    result = df[df['stat'] == stat]\n",
    "\n",
    "    # Group by player and sum the statistic amounts\n",
    "    result = result.groupby('player')['stat_amount'].sum().sort_values(ascending=False)\n",
    "\n",
    "    # Set the name of the Series and its index\n",
    "    result.name = stat\n",
    "    result.index.name = 'Player'\n",
    "\n",
    "    # Convert the Series to a DataFrame\n",
    "    result = result.to_frame()\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "859d029a0a1deb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# get_players_stat('Hero Damage Done')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c02504eb51e5a53d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# |exporti\n",
    "def avg_stats_per_game(stat: str, player: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function calculates the average amount of a specific statistic per game for a specific player.\n",
    "\n",
    "    Parameters:\n",
    "    stat (str): The statistic to consider.\n",
    "    player (str): The player to consider.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the average amount of the statistic per game for each hero the player has played, \n",
    "    the number of games played with each hero, sorted in descending order of the average statistic.\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame based on the statistic and player\n",
    "    player_data = df[(df['stat'] == stat) & (df['player'] == player)]\n",
    "    results = pd.DataFrame(columns=['Hero', 'Stat', 'Avg per game'])\n",
    "\n",
    "    # Filter the DataFrame based on the statistic\n",
    "    stat_data = player_data[player_data['stat'] == stat]\n",
    "\n",
    "    # Calculate the average statistic amount per game for each hero\n",
    "    avg_per_game = stat_data.groupby(['hero'])['stat_amount'].mean().reset_index()\n",
    "    avg_per_game.columns = ['Hero', 'Avg per game']\n",
    "\n",
    "    # Calculate the number of games played with each hero\n",
    "    avg_per_game['Number of game'] = stat_data.groupby(['hero'])['stat_amount'].count().reset_index()['stat_amount']\n",
    "\n",
    "    # Concatenate the results\n",
    "    results = pd.concat([results, avg_per_game], ignore_index=True, sort=False)\n",
    "\n",
    "    return results[['Hero', 'Avg per game', 'Number of game']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2117c7d3c4980543",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# |export\n",
    "def get_teams_leaderboard(stage=None):\n",
    "    \"\"\"\n",
    "    This function calculates the win rate for each team in the dataset, optionally for a specific stage.\n",
    "\n",
    "    Parameters:\n",
    "    stage (str, optional): The stage to consider. If None, all stages are considered.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the win rate for each team, sorted in descending order.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get a list of unique teams\n",
    "    teams = df['team'].unique()\n",
    "\n",
    "    # Initialize an empty list to store the win rates\n",
    "    winrates = []\n",
    "\n",
    "    # Calculate the win rate for each team\n",
    "    for team in teams:\n",
    "        # Get all matches involving the team\n",
    "        team_matches = df[(df['team'] == team)]\n",
    "\n",
    "        # If a stage is specified, filter the matches by stage\n",
    "        if stage is not None:\n",
    "            # Keep only rows where 'stage' is equal to the specified stage\n",
    "            team_matches = team_matches[team_matches['stage'] == stage]\n",
    "\n",
    "        # If team_matches is empty, continue to the next team\n",
    "        if team_matches.empty:\n",
    "            continue\n",
    "\n",
    "        # Get match_ids for the filtered matches\n",
    "        match_ids = team_matches['match_id'].unique()\n",
    "\n",
    "        # Filter map_stats by these match_ids\n",
    "        team_map_stats = map_stats[map_stats['match_id'].isin(match_ids)]\n",
    "\n",
    "        # Count the number of matches won by the team\n",
    "        wins = len(team_map_stats[team_map_stats['match_winner'] == team])\n",
    "\n",
    "        # Calculate the total number of matches played by the team\n",
    "        total_matches = len(team_map_stats)\n",
    "\n",
    "        # Calculate the win rate\n",
    "        if total_matches > 0:\n",
    "            winrate = (wins / total_matches) * 100\n",
    "        else:\n",
    "            winrate = 0\n",
    "\n",
    "        # Append the team and its win rate to the list\n",
    "        winrates.append((team, winrate))\n",
    "\n",
    "    # Convert the list to a DataFrame\n",
    "    winrates_df = pd.DataFrame(winrates, columns=['Team', 'Winrate'])\n",
    "\n",
    "    # Sort the DataFrame by win rate in descending order\n",
    "    winrates_df = winrates_df.sort_values('Winrate', ascending=False)\n",
    "\n",
    "    return winrates_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab6b4064970d73de",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# get_teams_leaderboard()",
   "metadata": {
    "collapsed": false
   },
   "id": "c4a62dbfb693e962",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# |export\n",
    "def get_heroes_stat_by_player(stat: str, player: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    This function calculates the total amount of a specific statistic for each hero played by a specific player.\n",
    "\n",
    "    Parameters:\n",
    "    stat (str): The statistic to consider.\n",
    "    player (str): The player to consider.\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: A Series containing the total amount of the statistic for each hero played by the player, \n",
    "    sorted in descending order, and the average statistic per game.\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame based on the statistic and player\n",
    "    result = df[(df['stat'] == stat) & (df['player'] == player)].groupby('hero')['stat_amount'].sum().sort_values(\n",
    "        ascending=False)\n",
    "    result.name = stat\n",
    "    result.index.name = 'Hero'\n",
    "\n",
    "    # Calculate the average statistic per game\n",
    "    stat_avg = avg_stats_per_game(stat, player)\n",
    "\n",
    "    # Merge the total and average statistics\n",
    "    result = result.reset_index().merge(stat_avg, on='Hero', how='left')\n",
    "\n",
    "    # Reset the index\n",
    "    result = result.set_index('Hero')\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a9787f3b5901826",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "990f5c86d8c8998c"
  },
  {
   "cell_type": "code",
   "source": [
    "# get_heroes_stat_by_player('Hero Damage Done', 'SoOn')\n",
    "# df.head()\n",
    "# avg_stats_per_game('SoOn')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7153fcad2db4a9f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# |export\n",
    "def get_players_stat_by_team(stat: str, team: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function calculates the total amount of a specific statistic for each player in a specific team.\n",
    "\n",
    "    Parameters:\n",
    "    stat (str): The statistic to consider.\n",
    "    team (str): The team to consider.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the total amount of the statistic for each player in the team, sorted in descending order.\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame based on the statistic and team\n",
    "    result = df[(df['stat'] == stat) & (df['team'] == team)].groupby('player')['stat_amount'].sum().sort_values(\n",
    "        ascending=False)\n",
    "\n",
    "    # Set the name of the Series and its index\n",
    "    result.name = stat\n",
    "    result.index.name = 'Player'\n",
    "    result = result.to_frame()\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81355387a68caeb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# get_players_stat_by_team('Hero Damage Done', 'Paris Eternal')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19ff4a3270061fd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# |export\n",
    "def get_team_scores(team: str, map_type: str = None, map_name: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function generates a DataFrame containing the scores of a specific team, optionally filtered by map type and map name.\n",
    "\n",
    "    Parameters:\n",
    "    team (str): The name of the team.\n",
    "    map_type (str, optional): The type of the map. If None, all map types are considered.\n",
    "    map_name (str, optional): The name of the map. If None, all maps are considered.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the scores of the team, including the number of wins, losses, and the win rate.\n",
    "    \"\"\"\n",
    "    # Stock every unique game from team (each game as a unique 'match_id'), team name is stocked in 'team_one_name' or 'team_two_name'\n",
    "    team_games = map_stats[(map_stats['team_one_name'] == team) | (map_stats['team_two_name'] == team)]\n",
    "    if map_type:  # only 1 row per game\n",
    "        # Add column 'map_type' from dataframe 'df'\n",
    "        team_games = team_games.merge(df[['match_id', 'map_type']], on='match_id')\n",
    "        team_games = team_games[team_games['map_type'].str.lower() == map_type.lower()]\n",
    "        if map_name:  # only 1 row per game\n",
    "            team_games = team_games[team_games['map_name'].str.lower() == map_name.lower()]\n",
    "        # Get one row per map\n",
    "        team_games = team_games.drop_duplicates(subset='round_start_time')\n",
    "        # Do not keep twice same game_number per match_id\n",
    "        df_grp = team_games.groupby(['match_id', 'game_number'])\n",
    "        team_games = df_grp.first().reset_index()\n",
    "    else:  # only 1 row per match\n",
    "        # Get one row per match\n",
    "        team_games = team_games.drop_duplicates(subset='match_id')\n",
    "\n",
    "    # Get teams list\n",
    "    opponents = team_games[['team_one_name', 'team_two_name']]\n",
    "    # Remove team input from opponents list\n",
    "    opponents = opponents[opponents != team]\n",
    "    # Regroup in one column and remove duplicates\n",
    "    opponents = opponents.stack().reset_index(drop=True).drop_duplicates()\n",
    "\n",
    "    results = pd.DataFrame(columns=['team', 'opponent', 'win', 'loss', 'winrate', 'map_type', 'only_matches'])\n",
    "\n",
    "    for opponent in opponents:\n",
    "        matches = team_games[((team_games['team_one_name'] == team) &\n",
    "                              (team_games['team_two_name'] == opponent)) | (\n",
    "                                     (team_games['team_one_name'] == opponent) & (team_games['team_two_name'] == team))]\n",
    "\n",
    "        if map_type:\n",
    "            wins = matches['map_winner'] == team\n",
    "        else:\n",
    "            wins = matches['match_winner'] == team\n",
    "\n",
    "        total_matches = matches.shape[0]\n",
    "        if total_matches == 0:\n",
    "            continue\n",
    "        wins = wins.sum()\n",
    "        losses = len(matches) - wins\n",
    "        winrate = wins / total_matches\n",
    "\n",
    "        row = pd.DataFrame(\n",
    "            {'team': team, 'opponent': opponent, 'total_matches': total_matches, 'win': wins, 'loss': losses,\n",
    "             'winrate': winrate * 100, 'map_type': map_type,\n",
    "             'only_matches': not map_type, 'map_name': map_name}, index=[0])\n",
    "        results = pd.concat([results, row])\n",
    "\n",
    "    # Rename columns\n",
    "    results.rename(columns={'team': 'Team', 'opponent': 'Opponent', 'total_matches': 'Total Matches', 'win': 'Win',\n",
    "                            'loss': 'Loss', 'winrate': 'Winrate', 'map_type': 'Map Type',\n",
    "                            'only_matches': 'Only Matches', 'map_name': 'Map Name'},\n",
    "                   inplace=True)\n",
    "\n",
    "    # Reorder columns\n",
    "    results = results[\n",
    "        ['Team', 'Opponent', 'Total Matches', 'Win', 'Loss', 'Winrate', 'Map Type', 'Map Name', 'Only Matches']]\n",
    "    if not map_type:\n",
    "        results = results.drop(columns='Map Type')\n",
    "    if not map_name:\n",
    "        results = results.drop(columns='Map Name')\n",
    "\n",
    "    results = results.set_index('Team')\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35050d14f1f2aaf4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# |export\n",
    "def get_switches() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function returns a DataFrame containing the switches made by players during matches.\n",
    "    \"\"\"\n",
    "    result = df_switch\n",
    "    return result"
   ],
   "id": "9fb287d8f714e1dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# get_team_scores('Dallas Fuel', 'Control', 'Nepal')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da43cd8fcfa32b3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# get every team in alphabetical order\n",
    "# df['team'].unique()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10bc4a3296879f81",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# get every map in alphabetical order\n",
    "# df['map'].unique()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f67a44fee9df0c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# get every hero in alphabetical order\n",
    "# df['hero'].unique()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1227d7ab661ef07",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from nbdev.export import nb_export\n",
    "\n",
    "nb_export(\"owl.ipynb\", lib_path=\"./\", name=\"owl_module\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d95a21067163bf79",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
